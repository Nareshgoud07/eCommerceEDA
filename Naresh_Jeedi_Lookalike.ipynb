{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a93c358c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\nanin\\anaconda3\\lib\\site-packages (1.4.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\nanin\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\nanin\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\nanin\\anaconda3\\lib\\site-packages (3.5.2)\n",
      "Requirement already satisfied: seaborn in c:\\users\\nanin\\anaconda3\\lib\\site-packages (0.11.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\nanin\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nanin\\anaconda3\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\nanin\\anaconda3\\lib\\site-packages (from scikit-learn) (1.9.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\nanin\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\nanin\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\nanin\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\nanin\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\nanin\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nanin\\anaconda3\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\nanin\\anaconda3\\lib\\site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\nanin\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nanin\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.24.4-cp39-cp39-win_amd64.whl.metadata (5.6 kB)\n",
      "Downloading numpy-1.24.4-cp39-cp39-win_amd64.whl (14.9 MB)\n",
      "   ---------------------------------------- 14.9/14.9 MB 3.4 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "Successfully installed numpy-1.24.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\nanin\\anaconda3\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\nanin\\anaconda3\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.6.0 requires daal==2021.4.0, which is not installed.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.24.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c8e8bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19c97865",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = pd.read_csv(r\"C:\\Users\\nanin\\OneDrive\\Desktop\\Customers (1).csv\")\n",
    "products = pd.read_csv(r\"C:\\Users\\nanin\\OneDrive\\Desktop\\Products.csv\")\n",
    "transactions = pd.read_csv(r\"C:\\Users\\nanin\\OneDrive\\Desktop\\Transactions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bf6c3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers Dataset:\n",
      "   CustomerID        CustomerName         Region  SignupDate\n",
      "0      C0001    Lawrence Carroll  South America  2022-07-10\n",
      "1      C0002      Elizabeth Lutz           Asia  2022-02-13\n",
      "2      C0003      Michael Rivera  South America  2024-03-07\n",
      "3      C0004  Kathleen Rodriguez  South America  2022-10-09\n",
      "4      C0005         Laura Weber           Asia  2022-08-15\n",
      "\n",
      "Products Dataset:\n",
      "   ProductID              ProductName     Category   Price\n",
      "0      P001     ActiveWear Biography        Books  169.30\n",
      "1      P002    ActiveWear Smartwatch  Electronics  346.30\n",
      "2      P003  ComfortLiving Biography        Books   44.12\n",
      "3      P004            BookWorld Rug   Home Decor   95.69\n",
      "4      P005          TechPro T-Shirt     Clothing  429.31\n",
      "\n",
      "Transactions Dataset:\n",
      "   TransactionID CustomerID ProductID      TransactionDate  Quantity  \\\n",
      "0        T00001      C0199      P067  2024-08-25 12:38:23         1   \n",
      "1        T00112      C0146      P067  2024-05-27 22:23:54         1   \n",
      "2        T00166      C0127      P067  2024-04-25 07:38:55         1   \n",
      "3        T00272      C0087      P067  2024-03-26 22:55:37         2   \n",
      "4        T00363      C0070      P067  2024-03-21 15:10:10         3   \n",
      "\n",
      "   TotalValue   Price  \n",
      "0      300.68  300.68  \n",
      "1      300.68  300.68  \n",
      "2      300.68  300.68  \n",
      "3      601.36  300.68  \n",
      "4      902.04  300.68  \n"
     ]
    }
   ],
   "source": [
    "print(\"Customers Dataset:\\n\", customers.head())\n",
    "print(\"\\nProducts Dataset:\\n\", products.head())\n",
    "print(\"\\nTransactions Dataset:\\n\", transactions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "647be06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in Customers:\n",
      " CustomerID      0\n",
      "CustomerName    0\n",
      "Region          0\n",
      "SignupDate      0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in Products:\n",
      " ProductID      0\n",
      "ProductName    0\n",
      "Category       0\n",
      "Price          0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in Transactions:\n",
      " TransactionID      0\n",
      "CustomerID         0\n",
      "ProductID          0\n",
      "TransactionDate    0\n",
      "Quantity           0\n",
      "TotalValue         0\n",
      "Price              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMissing values in Customers:\\n\", customers.isnull().sum())\n",
    "print(\"\\nMissing values in Products:\\n\", products.isnull().sum())\n",
    "print(\"\\nMissing values in Transactions:\\n\", transactions.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c9ab671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Customers Dataset Statistics:\n",
      "        CustomerID      CustomerName         Region  SignupDate\n",
      "count         200               200            200         200\n",
      "unique        200               200              4         179\n",
      "top         C0001  Lawrence Carroll  South America  2024-11-11\n",
      "freq            1                 1             59           3\n",
      "\n",
      "Products Dataset Statistics:\n",
      "        ProductID            ProductName Category       Price\n",
      "count        100                    100      100  100.000000\n",
      "unique       100                     66        4         NaN\n",
      "top         P001  ActiveWear Smartwatch    Books         NaN\n",
      "freq           1                      4       26         NaN\n",
      "mean         NaN                    NaN      NaN  267.551700\n",
      "std          NaN                    NaN      NaN  143.219383\n",
      "min          NaN                    NaN      NaN   16.080000\n",
      "25%          NaN                    NaN      NaN  147.767500\n",
      "50%          NaN                    NaN      NaN  292.875000\n",
      "75%          NaN                    NaN      NaN  397.090000\n",
      "max          NaN                    NaN      NaN  497.760000\n",
      "\n",
      "Transactions Dataset Statistics:\n",
      "           Quantity   TotalValue       Price\n",
      "count  1000.000000  1000.000000  1000.00000\n",
      "mean      2.537000   689.995560   272.55407\n",
      "std       1.117981   493.144478   140.73639\n",
      "min       1.000000    16.080000    16.08000\n",
      "25%       2.000000   295.295000   147.95000\n",
      "50%       3.000000   588.880000   299.93000\n",
      "75%       4.000000  1011.660000   404.40000\n",
      "max       4.000000  1991.040000   497.76000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCustomers Dataset Statistics:\\n\", customers.describe(include='all'))\n",
    "print(\"\\nProducts Dataset Statistics:\\n\", products.describe(include='all'))\n",
    "print(\"\\nTransactions Dataset Statistics:\\n\", transactions.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9577665",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(transactions, customers, on='CustomerID', how='left')\n",
    "merged_data = pd.merge(merged_data, products, on='ProductID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce234dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged Dataset:\n",
      "   TransactionID CustomerID ProductID      TransactionDate  Quantity  \\\n",
      "0        T00001      C0199      P067  2024-08-25 12:38:23         1   \n",
      "1        T00112      C0146      P067  2024-05-27 22:23:54         1   \n",
      "2        T00166      C0127      P067  2024-04-25 07:38:55         1   \n",
      "3        T00272      C0087      P067  2024-03-26 22:55:37         2   \n",
      "4        T00363      C0070      P067  2024-03-21 15:10:10         3   \n",
      "\n",
      "   TotalValue  Price_x     CustomerName         Region  SignupDate  \\\n",
      "0      300.68   300.68   Andrea Jenkins         Europe  2022-12-03   \n",
      "1      300.68   300.68  Brittany Harvey           Asia  2024-09-04   \n",
      "2      300.68   300.68  Kathryn Stevens         Europe  2024-04-04   \n",
      "3      601.36   300.68  Travis Campbell  South America  2024-04-11   \n",
      "4      902.04   300.68    Timothy Perez         Europe  2022-03-15   \n",
      "\n",
      "                       ProductName     Category  Price_y  \n",
      "0  ComfortLiving Bluetooth Speaker  Electronics   300.68  \n",
      "1  ComfortLiving Bluetooth Speaker  Electronics   300.68  \n",
      "2  ComfortLiving Bluetooth Speaker  Electronics   300.68  \n",
      "3  ComfortLiving Bluetooth Speaker  Electronics   300.68  \n",
      "4  ComfortLiving Bluetooth Speaker  Electronics   300.68  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMerged Dataset:\\n\", merged_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "412c2e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_summary = merged_data.groupby('CustomerID').agg({\n",
    "    'TotalValue': 'sum',\n",
    "    'Quantity': 'sum'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b77974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_data = pd.merge(customer_summary, customers, on='CustomerID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b90aa132",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_data_encoded = pd.get_dummies(customer_data, columns=['Region'], drop_first=True)\n",
    "scaler = StandardScaler()\n",
    "numerical_features = ['TotalValue', 'Quantity']\n",
    "customer_data_encoded[numerical_features] = scaler.fit_transform(customer_data_encoded[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "127b9656",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = cosine_similarity(customer_data_encoded.drop(columns=['CustomerID', 'CustomerName', 'SignupDate']))\n",
    "similarity_df = pd.DataFrame(similarity_matrix, index=customer_data['CustomerID'], columns=customer_data['CustomerID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fd04681",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookalike_results = {}\n",
    "for customer_id in similarity_df.index:\n",
    "    similar_customers = similarity_df[customer_id].sort_values(ascending=False).iloc[1:4]\n",
    "    lookalike_results[customer_id] = list(zip(similar_customers.index, similar_customers.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c18f50c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lookalike recommendations saved to Lookalike.csv\n"
     ]
    }
   ],
   "source": [
    "lookalike_data = []\n",
    "for customer_id, lookalikes in lookalike_results.items():\n",
    "    for similar_id, score in lookalikes:\n",
    "        lookalike_data.append([customer_id, similar_id, score])\n",
    "\n",
    "lookalike_df = pd.DataFrame(lookalike_data, columns=['CustomerID', 'SimilarCustomerID', 'SimilarityScore'])\n",
    "lookalike_df.to_csv(\"/mnt/data/Lookalike.csv\", index=False)\n",
    "print(\"\\nLookalike recommendations saved to Lookalike.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc730a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.to_csv(\"/mnt/data/MergedDataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a84c87ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'customer_profiles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14504\\2200063417.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlookalike_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mcust_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcustomer_profiles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CustomerID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mlookalikes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_top_lookalikes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimilarity_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mlookalike_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcust_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlookalikes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'customer_profiles' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "lookalike_results = {}\n",
    "for idx in range(20):  \n",
    "    cust_id = customer_profiles.iloc[idx]['CustomerID']\n",
    "    lookalikes = get_top_lookalikes(idx, similarity_matrix)\n",
    "    lookalike_results[cust_id] = lookalikes\n",
    "\n",
    "lookalike_csv_data = []\n",
    "for cust_id, lookalikes in lookalike_results.items():\n",
    "    row = [cust_id]\n",
    "    for lookalike_id, score in lookalikes:\n",
    "        row.extend([lookalike_id, score])\n",
    "    lookalike_csv_data.append(row)\n",
    "\n",
    "columns = ['CustomerID', 'Lookalike1', 'Score1', 'Lookalike2', 'Score2', 'Lookalike3', 'Score3']\n",
    "lookalike_df = pd.DataFrame(lookalike_csv_data, columns=columns)\n",
    "\n",
    "\n",
    "lookalike_df.to_csv('Naresh_Goud_Lookalike.csv', index=False)\n",
    "\n",
    "print(\"Naresh_Goud_Lookalike.csv saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5fbc414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CustomerID        CustomerName         Region  SignupDate  TotalSpending  \\\n",
      "0      C0001    Lawrence Carroll  South America  2022-07-10        3354.52   \n",
      "1      C0002      Elizabeth Lutz           Asia  2022-02-13        1862.74   \n",
      "2      C0003      Michael Rivera  South America  2024-03-07        2725.38   \n",
      "3      C0004  Kathleen Rodriguez  South America  2022-10-09        5354.88   \n",
      "4      C0005         Laura Weber           Asia  2022-08-15        2034.24   \n",
      "\n",
      "   AvgTransactionValue  TransactionCount  UniqueProducts  \\\n",
      "0              670.904               5.0             5.0   \n",
      "1              465.685               4.0             4.0   \n",
      "2              681.345               4.0             4.0   \n",
      "3              669.360               8.0             8.0   \n",
      "4              678.080               3.0             3.0   \n",
      "\n",
      "                                            Features  \n",
      "0  [0.3142740168280109, 0.50705698594246, 0.45454...  \n",
      "1  [0.17451402349850617, 0.351956215045095, 0.363...  \n",
      "2  [0.2553319461451189, 0.5149481029878572, 0.363...  \n",
      "3  [0.5016812084089464, 0.505890058950975, 0.7272...  \n",
      "4  [0.19058129806714905, 0.5124804756386356, 0.27...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "customer_features = merged_data.groupby('CustomerID').agg({\n",
    "    'TotalValue': ['sum', 'mean'], \n",
    "    'TransactionID': 'count',\n",
    "    'ProductID': lambda x: x.nunique()\n",
    "}).reset_index()\n",
    "\n",
    "\n",
    "customer_features.columns = ['CustomerID', 'TotalSpending', 'AvgTransactionValue', 'TransactionCount', 'UniqueProducts']\n",
    "\n",
    "customer_profiles = customers.merge(customer_features, on='CustomerID', how='left')\n",
    "customer_profiles.fillna(0, inplace=True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = scaler.fit_transform(customer_profiles[['TotalSpending', 'AvgTransactionValue', 'TransactionCount', 'UniqueProducts']])\n",
    "customer_profiles['Features'] = list(scaled_features)\n",
    "\n",
    "print(customer_profiles.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3afd1b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naresh_Jeedi_Lookalike.csv saved successfully!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity_matrix = cosine_similarity(scaled_features)\n",
    "\n",
    "def get_top_lookalikes(customer_index, similarity_matrix, top_n=3):\n",
    "    similarities = similarity_matrix[customer_index]\n",
    "    similar_indices = np.argsort(-similarities)[1:top_n+1]  \n",
    "    return [(customer_profiles.iloc[i]['CustomerID'], similarities[i]) for i in similar_indices]\n",
    "\n",
    "\n",
    "lookalike_results = {}\n",
    "for idx in range(20):\n",
    "    cust_id = customer_profiles.iloc[idx]['CustomerID']\n",
    "    lookalikes = get_top_lookalikes(idx, similarity_matrix)\n",
    "    lookalike_results[cust_id] = lookalikes\n",
    "\n",
    "lookalike_csv_data = []\n",
    "for cust_id, lookalikes in lookalike_results.items():\n",
    "    row = [cust_id]\n",
    "    for lookalike_id, score in lookalikes:\n",
    "        row.extend([lookalike_id, score])\n",
    "    lookalike_csv_data.append(row)\n",
    "\n",
    "\n",
    "columns = ['CustomerID', 'Lookalike1', 'Score1', 'Lookalike2', 'Score2', 'Lookalike3', 'Score3']\n",
    "lookalike_df = pd.DataFrame(lookalike_csv_data, columns=columns)\n",
    "\n",
    "lookalike_df.to_csv('Naresh_Jeedi_Lookalike.csv', index=False)\n",
    "\n",
    "print(\"Naresh_Jeedi_Lookalike.csv saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2561573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8c9b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
